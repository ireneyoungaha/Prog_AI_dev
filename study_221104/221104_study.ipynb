{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5-1 검증 세트, 전처리 과정\n",
    "5-2 과대적합/과소적합\n",
    "5-3 규제 방법\n",
    "5-4 교차 검증 \n",
    "\n",
    "테스트 세트는 어떤 한 데이터 세트에 대해서도 치우치지 않게끔."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-1 검증 세트, 전처리 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "x, y  = cancer.data, cancer.target\n",
    "\n",
    "#전체를 학습, 테스트로 쪼개기\n",
    "x_train_all, x_test, y_train_all, y_test = train_test_split(x,y,stratify = y, test_size = 0.2, random_state= 42)\n",
    "\n",
    "\n",
    "sgd = SGDClassifier(loss = 'log', random_state = 42)\n",
    "sgd.fit(x_train_all,y_train_all)\n",
    "sgd.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier(loss = 'hinge', random_state = 42)\n",
    "sgd.fit(x_train_all,y_train_all)\n",
    "sgd.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function을 바꾸어가면서 성능을 개선시킬 수 있다. => 모델 튜닝 작업. 하지만 과연 실전에서도 좋은 성능을 낼까? \n",
    "일반화 성능의 왜곡: 테스트 세트로 모델 튜닝을 하면 실제 성능이 좋기 어렵다. \n",
    "따라서 모델 튜닝에 테스트 세트를 사용하지 않아야 한다. 튜닝용도의 검증 세트는 훈련세트를 조금 떼어서 사용한다. (훈6 검2 테2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습을 학습, 검증으로 쪼개기\n",
    "x_train,x_val,y_train, y_val = train_test_split(x_train_all, y_train_all, stratify=y_train_all, test_size = 0.2, random_state=42)\n",
    "\n",
    "print(len(x_train),len(x_val))\n",
    "\n",
    "sgd = SGDClassifier(loss = 'log_loss', random_state = 42)\n",
    "sgd.fit(x_train,y_train)\n",
    "sgd.score(x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "교차 검증을 데이터 양이 적을 때 사용할 수 있다. \n",
    "10만개 8:1:1, 100만개 98:1:1 정도로 나눈다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 전처리, 특성의 스케일\n",
    "\n",
    "\n",
    "<img src = '01.jpg' />\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특성의 스케일(값의 범위)을 조정해서 모델을 안정화시킬 수 있다.\n",
    "\n",
    "평균이 0, 분산이 1인 특성으로 만드는 표준화 공식 : \n",
    "\n",
    "$$z = \\frac{x - \\mu}{s}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#추가사항들을 반영한 SingleLayer \n",
    "class SingleLayer:\n",
    "    def __init__(self, learning_rate = 0.1, l1 = 0, l2 = 0):\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        self.lr = learning_rate\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.w_history = []\n",
    "        self.l1 = l1\n",
    "        self.l2 = l2\n",
    "        \n",
    "    def forpass(self, x):\n",
    "        z = np.sum(x * self.w) + self.b\n",
    "        return z\n",
    "    \n",
    "    def backprop(self, x, err):\n",
    "        w_grad = x * err\n",
    "        b_grad = 1 * err\n",
    "        return w_grad, b_grad\n",
    "    \n",
    "    def activation(self, z): # z is an numpy array\n",
    "        a = 1 / (1 + np.exp(-z))\n",
    "        return a\n",
    "    \n",
    "    def fit(self, x, y, epochs=100, x_val = None, y_val = None):\n",
    "        self.w = np.ones(x.shape[1]) # x.shape[1] : feature 개수\n",
    "        self.b = 0\n",
    "        self.w_history.append(self.w.copy())\n",
    "        np.random.seed(42)\n",
    "        for i in range(epochs):\n",
    "            loss = 0\n",
    "            indexes = np.random.permutation(np.arange(len(x))) # 샘플 순서 섞기\n",
    "            for i in indexes:\n",
    "                z = self.forpass(x[i])\n",
    "                a = self.activation(z)\n",
    "                err = -(y[i] - a)\n",
    "                w_grad, b_grad = self.backprop(x[i], err)\n",
    "                self.w -= w_grad * self.lr\n",
    "                self.b -= b_grad\n",
    "                self.w_history.append(self.w.copy())\n",
    "                a = np.clip(a, 1e-10, 1-1e-10)\n",
    "                loss += -(y[i]*np.log(a) + (1-y[i])*np.log(1-a))    \n",
    "            self.losses.append(loss/len(y) + self.reg_loss()) #에포크마다의 평균 손실\n",
    "            self.update_val_loss(x_val, y_val) #검증세트에 대한 손실\n",
    "    \n",
    "    def reg_loss(self) :\n",
    "        return self.l1*np.sum(np.abs(self.w)) + self.l2 / 2 * np.sum(self.w**2)\n",
    "                     \n",
    "    def predict(self, x):\n",
    "        z = [self.forpass(x_i) for x_i in x]\n",
    "        # a = self.activation(np.array(z))\n",
    "        # return a > 0.5        \n",
    "        return np.array(z) > 0\n",
    "    \n",
    "    def forpass_batch(self, x):\n",
    "        z = np.dot(x, self.w) + self.b\n",
    "        return z\n",
    "    \n",
    "    def backprop_batch(self, x, err):\n",
    "        m = len(x)\n",
    "        w_grad = np.dot(x.T, err) / m\n",
    "        b_grad = np.sum(err) / m\n",
    "        return w_grad, b_grad\n",
    "    \n",
    "    def fit_batch(self, x, y, epochs=100):\n",
    "        y = y.reshape(-1, 1)\n",
    "        m = len(x)\n",
    "        self.w = np.ones((x.shape[1], 1))\n",
    "        self.b = 0\n",
    "\n",
    "        for i in range(epochs):\n",
    "            z = self.forpass_batch(x)\n",
    "            a = self.activation(z)\n",
    "            err = -(y - a)\n",
    "            w_grad, b_grad = self.backprop_batch(x, err)\n",
    "            self.w -= self.lr * w_grad\n",
    "            self.b -= self.lr * b_grad\n",
    "            a = np.clip(a, 1e-10, 1-1e-10)\n",
    "            loss = np.sum(-(y*np.log(a) + (1-y)*np.log(1-a)))\n",
    "            self.losses.append(loss / m)\n",
    "    \n",
    "    def predict_batch(self, x):\n",
    "        z = self.forpass_batch(x)\n",
    "        return np.array(z) > 0\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        return np.mean(self.predict(x) == y)\n",
    "    \n",
    "    def update_val_loss(self, x_val, y_val) : \n",
    "        if x_val is None:\n",
    "            return\n",
    "        val_loss = 0\n",
    "        for i in range(len(x_val)) :\n",
    "            z = self.forpass(x_val[i])\n",
    "            a = self.activation(z)\n",
    "            a = np.clip(a, 1e-10, 1-1e-10)\n",
    "            val_loss += -(y_val[i]*np.log(a) + (1-y_val[i])*np.log(1-a))\n",
    "        self.val_losses.append(val_loss/len(y_val) + self.reg_loss())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 유방암 데이터\n",
    "\n",
    "mean perimiter, mean area 특성 스케일 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cancer.feature_names[[2,3]])\n",
    "plt.boxplot(x_train[:,2:4])\n",
    "plt.xlabel('feature')\n",
    "plt.ylabel('value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1=SingleLayer()\n",
    "layer1.fit(x_train,y_train)\n",
    "layer1.score(x_val,y_val)\n",
    "\n",
    "w2, w3 = [], []\n",
    "for w in layer1.w_history:\n",
    "    w2.append(w[2])\n",
    "    w3.append(w[3])\n",
    "plt.plot(w2,w3)\n",
    "plt.plot(w2[-1],w3[-1],'ro')\n",
    "plt.xlabel('w[2]')\n",
    "plt.ylabel('w[3]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scikitlearn's StandardScaler class equivalent standardization\n",
    "\n",
    "train_mean = np.mean(x_train, axis = 0)\n",
    "train_std = np.std(x_train, axis=0)\n",
    "x_train_scaled = (x_train-train_mean) / train_std\n",
    "\n",
    "layer2 = SingleLayer()\n",
    "layer2.fit(x_train_scaled, y_train)\n",
    "w2, w3 = [], []\n",
    "for w in layer2.w_history:\n",
    "    w2.append(w[2])\n",
    "    w3.append(w[3])\n",
    "plt.plot(w2,w3)\n",
    "plt.plot(w2[-1],w3[-1],'ro')\n",
    "plt.xlabel('w[2]')\n",
    "plt.ylabel('w[3]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w2, w3의 변화 비율이 비슷하기 때문에 가중치가 대각선 반향으로 이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2.score(x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 수치는 검증세트의 스케일은 정규화 해주지 않았기 때문, 검증세트도 표준화해야 한다.\n",
    "\n",
    "* 함정: 훈련세트와 검증세트가 다른 비율로 전처리 될 수 있다. \n",
    "* 해결방법 : 훈련세트의 평균, 표준 편차를 사용하여 검증세트를 변환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_mean = np.mean(x_val, axis = 0) #특성별 평균\n",
    "val_std = np.std(x_val, axis = 0)\n",
    "\n",
    "x_val_scaled = (x_val - val_mean) / train_std\n",
    "layer2.score(x_val_scaled, y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과대적합과 과소적합\n",
    "\n",
    "훈련세트에 대한 학습 곡선(learning curve)\n",
    "\n",
    "<img src = '02.jpg' />\n",
    "\n",
    "1. 과대적합\n",
    "    1. 훈련세트와 검증 세트의 성능차 크다 => 분산이 크다\n",
    "    2. 원인 : 훈련세트에 다양한 패턴의 샘플이 없음\n",
    "    3. 해결 : 더 많은 훈련 샘플, 가중치 제한으로 모델의 복잡도 저하\n",
    "2. 과소적합\n",
    "    1. 성능 자체가 낮다 =>편향이 크다\n",
    "    2. 원인 : 모델이 충분히 복잡하지 않아 훈련 데이터에 있는 패턴을 모두 잡지 못함\n",
    "    3. 해결 : 모델의 복잡도 증가, 가중치 규제 완화\n",
    "3. 절충점, 좋은 모델\n",
    "\n",
    "에포크/모델복잡도에 대한 학습 곡선(learning curve)\n",
    "![3](03.jpg)\n",
    "\n",
    "1. 손실\n",
    "    1. 최적점 이전에 훈련세트 손실 감소, 검증세트의 손실 감소 => 과소적합\n",
    "    2. 최적점 이후에 훈련세트 손실 감소, 검증세트의 손실 상승 => 과대적합\n",
    "2. 정확도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 편향-분산 트레이드오프 \n",
    "정의 : 과소적합(편향)된 모델과 과대적합(분산)된 모델 사이의 관계. 둘 다 완전히 잡을 수는 없으므로 적절한 중간 지점 선택\n",
    "\n",
    "#### 경사 하강법의 에포크 횟수에 대한 손실\n",
    "* SingleLayer()에 val_losses 변수, update_val_loss() 메서드 추가\n",
    "* 검증세트의 출력값의 로지스틱 손실 함수 값을 계산해서 `update_val-loss()`호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer3 = SingleLayer()\n",
    "layer3.fit(x_train_scaled,y_train, x_val = x_val_scaled, y_val = y_val)\n",
    "layer3.score(x_val_scaled, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylim(0,0.3)\n",
    "plt.plot(layer3.losses)\n",
    "plt.plot(layer3.val_losses)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epch')\n",
    "plt.legend(['train_loss','val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검증 손실이 20번째 에포크 이후에는 훈련 세트보다 높아지므로 20번까지만 훈련하면 된다-> 훈련 조기 종료로 과대적합 막기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer4 = SingleLayer()\n",
    "layer4.fit(x_train_scaled,y_train, x_val = x_val_scaled, y_val = y_val, epochs = 20)\n",
    "layer4.score(x_val_scaled, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-3 모델 규제 방법\n",
    "\n",
    "규제(regularization): 과대적합을 해결하는 방법 중 하나로 가중치의 값이 커지지 않도록 제한하여 모델의 일반화 성능이 올라간다.\n",
    "\n",
    "#### L1 규제 - 라쏘 모델\n",
    "\n",
    "* 손실함수에 가중치의 절대값을 손실함수에 더한 것\n",
    "\n",
    "$$||w||_1 = \\sum^n_{i=1}|w_i|$$\n",
    "\n",
    "<img src = '04.jpg' />\n",
    "\n",
    "$L$을 미분하여 얻은 도함수\\* 학습률로 가중치 업데이트\n",
    "\n",
    "<img src = '05.jpg' />\n",
    "\n",
    "* 규제 하이퍼파라미터 $\\alpha$와 가중치의 부호의 곱을 더하면 경사하강법을 최적화할 수 있다. \n",
    "* 절편은 모델을 shifting만 하므로 대해 규제를 하지 않는다.\n",
    "* 일부 가중치를 0으로 만들어 특성을 선택하는 효과를 낼 수 있다.\n",
    "* 가중치의 크기에 따라 규제량이 변하지 않으므로($\\alpha$에 많이 의존) 규제효과 좋지 않다.\n",
    "\n",
    "\n",
    "### L2 규제 - 릿지 모델\n",
    "\n",
    "* 손실함수에 가중치의 L2노름의 제곱을 더한 것\n",
    "\n",
    "$$||w||_2 = \\sqrt{\\sum^n_{i=1}w_i^2}$$\n",
    "\n",
    "<img src = '06.jpg' />\n",
    "\n",
    "$L$을 미분하여 얻은 도함수\\* 학습률로 가중치 업데이트\n",
    "\n",
    "<img src = '07.jpg' />\n",
    "\n",
    "* 규제 하이퍼파라미터 $\\alpha$와 가중치의 곱을 더하면 경사하강법을 최적화할 수 있다. \n",
    "* 가중치값 자체가 그래디언트를 업데이트할 때 쓰이므로 규제가 조금 더 효과적이다.\n",
    "* 가중치를 완전히 0으로 만들지 않아 복잡도가 떨어지지 않는다.\n",
    "\n",
    "#### 데이터 세트에 규제 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#L1 norm\n",
    "layer5 = SingleLayer(l1 = 0.001)\n",
    "layer5.fit(x_train_scaled, y_train, epochs = 20)\n",
    "layer5.score(x_val_scaled, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#L1 norm\n",
    "layer6 = SingleLayer(l2 = 0.001)\n",
    "layer6.fit(x_train_scaled, y_train, epochs = 20)\n",
    "layer6.score(x_val_scaled, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "샘플 개수가 적어서 성능차이가 없이 보인다. > 둘 다 검증 샘플에 대해 옳게 예측한 샘플 개수 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SGDClassifier 사용\n",
    "sgd = SGDClassifier(loss = 'log_loss',penalty = 'l2', alpha = 0.001, random_state = 42)\n",
    "sgd.fit(x_train_scaled, y_train)\n",
    "sgd.score(x_val_scaled, y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-4 교차 검증\n",
    "\n",
    "* 전체 데이터 샘플이 많지 않아 모델을 학습시키는 데이터가 부족할 때 교차 검증을 사용하면 좋다.\n",
    "\n",
    "* 전체 데이터를 5등분하여 그중 한조각(테스트세트)만 빼놓고 다시 k등분하여 한조각씩 빼두어 검증에, 나머지는 훈련에 사용한다.\n",
    "<img src = '08.jpg' />\n",
    "\n",
    "<img src = '09.jpg' />\n",
    "\n",
    "#### k-fold CV (k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_scores = []\n",
    "k = 10\n",
    "bins = len(x_train) // k\n",
    "\n",
    "for i in range(k) :\n",
    "    start = i*bins\n",
    "    end = (i+1)*bins\n",
    "    val_fold = x_train_all[start:end]\n",
    "    val_target = y_train_all[start:end]\n",
    "    \n",
    "    train_index = list(range(0, start)) + list(range(end, len(x_train)))\n",
    "    train_fold = x_train_all[train_index]\n",
    "    train_target = y_train_all[train_index]\n",
    "    \n",
    "    train_mean = np.mean(train_fold, axis = 0)\n",
    "    train_std = np.std(train_fold, axis = 0)\n",
    "    train_fold_scaled = (train_fold - train_mean) / train_std\n",
    "    val_fold_scaled = (val_fold - train_mean) / train_std\n",
    "    \n",
    "    lyr = SingleLayer(l2 = 0.01)\n",
    "    lyr.fit(train_fold_scaled, train_target, epochs = 50)\n",
    "    score = lyr.score(val_fold_scaled, val_target)\n",
    "    validation_scores.append(score)\n",
    "    \n",
    "print(np.mean(validation_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sgd = SGDClassifier(loss = 'log_loss', penalty='l2', alpha = 0.001, random_state = 42)\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), sgd)\n",
    "scores = cross_validate(pipe, x_train_all, y_train_all, cv = 10, return_train_score = True)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(scores['test_score'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "e0c1962a52e198cc006b1029570b749a138b14c8a17faf1cdd9dc804330f3c59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
